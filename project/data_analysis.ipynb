{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415a3298",
   "metadata": {},
   "source": [
    "# Gendered Reception of Politicians in Online Political Discourse\n",
    "\n",
    "### Computational Social Sciences\n",
    "\n",
    "**Authors:** BELLAIS Salome, GONZALEZ DARDIK Micaela Natali, MARCULESCU Tudor, RODRIGUEZ Miguel, VIELLARD Mathilde.\n",
    "**Course:** Computational Social Sciences (2025â€“2026)\n",
    "\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "\n",
    "Online social media platforms are key arenas for political debate, shaping public perception of political figures. While prior research highlights that female politicians often face different forms of evaluation and criticism than their male counterparts, frequently involving gendered language and personal attacks, data availability can limit broad generalizations.\n",
    "\n",
    "In this project, we focus on the online reception of selected French political figures, primarily Marine Le Pen and Emmanuel Macron, with additional data on a male politician from a similar ideological background. Using computational methods, we analyze textual content and interaction patterns on Twitter to examine differences in sentiment, toxicity, thematic focus, and network dynamics.\n",
    "\n",
    "By combining natural language processing techniques with graph-based analysis, this study investigates how gender and political alignment intersect in shaping online discourse, while explicitly acknowledging the methodological and ethical limitations inherent in computational social science approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ffed0f",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Social media platforms play a central role in contemporary political communication, allowing direct interaction between political figures and the public. While these platforms can foster political engagement, they also expose public figures to large volumes of unmoderated commentary, including harassment and hate speech.\n",
    "\n",
    "Gender bias in political communication has been documented in traditional media, where women are often evaluated based on personal attributes rather than political positions. Online platforms introduce additional dynamics such as anonymity, virality, and network effects, which may amplify these biases.\n",
    "\n",
    "In this project, we focus on the online reception of selected French political figures, primarily Marine Le Pen and Emmanuel Macron, with additional data on a male politician from a similar ideological background. Using computational tools, we aim to systematically analyze large-scale online discourse and examine how gender and political alignment intersect in shaping public perception and online commentary.\n",
    "\n",
    "Importantly, this study does not aim to establish causal claims about gender discrimination.\n",
    "Rather, it documents systematic differences in online reception under conditions where\n",
    "gender and political alignment are tightly intertwined, using computational tools to\n",
    "characterize large-scale discourse patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117ae41",
   "metadata": {},
   "source": [
    "## 2. Research Question and Hypotheses\n",
    "\n",
    "### Research Question\n",
    "\n",
    "How does the online reception of Marine Le Pen differ from that of Emmanuel Macron on Twitter, and to what extent can observed differences be associated with gender versus political alignment?\n",
    "\n",
    "### Sub-questions\n",
    "\n",
    "- Are tweets referring to Marine Le Pen more negative or toxic than those referring to Emmanuel Macron?  \n",
    "- Do the dominant topics differ between discussions about these politicians?  \n",
    "- Are gendered or personal themes (e.g. appearance, legitimacy, personal life) more prevalent in tweets about Marine Le Pen?  \n",
    "- How does the reception of Marine Le Pen compare to that of a male politician from a similar ideological background?\n",
    "\n",
    "### Hypotheses\n",
    "\n",
    "- **H1:** Tweets referring to Marine Le Pen exhibit higher levels of toxicity and personal attacks than those referring to Emmanuel Macron.  \n",
    "- **H2:** Differences in online reception are reflected not only in overall toxicity levels,\n",
    "but also in the qualitative composition of toxic language (e.g. insults, identity attacks).\n",
    "- **H3:** Differences in toxicity and interaction patterns persist, though are partially reduced, when comparing Marine Le Pen to a male politician from a similar political orientation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c42d0ee",
   "metadata": {},
   "source": [
    "## 3. Methodology\n",
    "\n",
    "We adopt a computational approach combining text and network analysis on Twitter data mentioning selected French political figures. Our pipeline includes:\n",
    "\n",
    "- **Natural Language Processing (NLP)**\n",
    "  - Text preprocessing: tokenization, cleaning, normalization\n",
    "  - Sentiment and toxicity classification (pre-trained models)\n",
    "  - Topic modeling for dominant themes\n",
    "- **Graph Analysis**\n",
    "  - Reply and interaction networks\n",
    "  - Centrality, clustering, and coordination patterns\n",
    "- **Robustness Considerations**\n",
    "  - Pre-trained models may encode biases\n",
    "  - Gender and political alignment are partially confounded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd278138",
   "metadata": {},
   "source": [
    "## Gender Versus Political Alignment\n",
    "\n",
    "A key limitation of the comparison between Marine Le Pen and Emmanuel Macron\n",
    "is that gender and political alignment are confounded.\n",
    "\n",
    "To partially disentangle these effects, we compare Marine Le Pen to a male\n",
    "politician from a similar ideological background. While differences in online\n",
    "reception are reduced in this comparison, they do not disappear entirely.\n",
    "\n",
    "This suggests that political alignment explains partâ€”but not allâ€”of the observed\n",
    "negativity gap, leaving room for gendered dynamics in online political discourse.\n",
    "\n",
    "\n",
    "## Limitations\n",
    "\n",
    "- Dataset limited to Twitter; may not generalize offline\n",
    "- NLP models carry social/cultural biases\n",
    "- Gender and political alignment are confounded; causal inference not possible\n",
    "- Imbalance in tweet counts requires careful interpretation of effect sizes\n",
    "\n",
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "This project relies exclusively on publicly available data and does not attempt\n",
    "to identify or profile individual users.\n",
    "\n",
    "All analyses are conducted at an aggregate level, focusing on discourse patterns\n",
    "rather than personal behavior. Particular care is taken in interpreting toxicity\n",
    "scores, which represent probabilistic model outputs rather than objective truths.\n",
    "\n",
    "By emphasizing effect sizes, uncertainty, and robustness, the study aligns with\n",
    "best practices in responsible computational social science.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a71734",
   "metadata": {},
   "source": [
    "## From Research Question to Empirical Strategy\n",
    "\n",
    "The research question guiding this project asks whether differences in online reception\n",
    "between Marine Le Pen and Emmanuel Macron can be attributed to gender, political alignment,\n",
    "or a combination of both.\n",
    "\n",
    "To answer this question, we adopt a step-by-step empirical strategy:\n",
    "\n",
    "1. **Establish a baseline** by comparing overall negativity and toxicity levels between the two politicians.\n",
    "2. **Assess the magnitude** of observed differences using both visualizations and statistical tests.\n",
    "3. **Disaggregate toxicity** into specific dimensions (insults, obscenity, identity attacks).\n",
    "4. **Examine temporal dynamics** to evaluate whether differences are stable or event-driven.\n",
    "5. **Explore textual and structural features** (tweet length, sentiment confidence) to rule out alternative explanations.\n",
    "\n",
    "The following sections implement this strategy using preprocessed Twitter data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1b7d801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\micag\\\\anaconda3\\\\envs\\\\css_full\\\\python.exe'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "\n",
    "# INSTALL ALL OF THIS LIBRARIES BEFORE RUNNING THE CODE\n",
    "# %pip install pandas numpy matplotlib seaborn nltk scikit-learn networkx transformers torch wordcloud textblob kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe23c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: detoxify in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (0.5.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from detoxify) (4.57.3)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from detoxify) (2.3.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.94 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from detoxify) (0.2.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from torch>=1.7.0->detoxify) (3.20.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from torch>=1.7.0->detoxify) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from torch>=1.7.0->detoxify) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from torch>=1.7.0->detoxify) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from torch>=1.7.0->detoxify) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from torch>=1.7.0->detoxify) (2025.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from torch>=1.7.0->detoxify) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.7.0->detoxify) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.7.0->detoxify) (2021.13.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from jinja2->torch>=1.7.0->detoxify) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from sympy->torch>=1.7.0->detoxify) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from transformers->detoxify) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from transformers->detoxify) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from transformers->detoxify) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from transformers->detoxify) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from transformers->detoxify) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from transformers->detoxify) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from transformers->detoxify) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from transformers->detoxify) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from transformers->detoxify) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from tqdm>=4.27->transformers->detoxify) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from requests->transformers->detoxify) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from requests->transformers->detoxify) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from requests->transformers->detoxify) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\micag\\anaconda3\\envs\\css_full\\lib\\site-packages (from requests->transformers->detoxify) (2026.1.4)\n",
      "Environment ready\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas numpy matplotlib seaborn nltk scikit-learn networkx transformers torch wordcloud textblob kagglehub detoxify\n",
    "!pip install detoxify\n",
    "\n",
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Topic modeling\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Graphs\n",
    "import networkx as nx\n",
    "\n",
    "# Utils\n",
    "from collections import Counter\n",
    "\n",
    "# Kagglehub for dataset download\n",
    "import kagglehub\n",
    "\n",
    "# install torch and after, transformers\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import detoxify\n",
    "\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu\n",
    "\n",
    "\n",
    "print(\"Environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90153f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\micag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\micag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038afef5",
   "metadata": {},
   "source": [
    "## 4. Data Sources\n",
    "\n",
    "Due to access restrictions and recent changes in the Twitter/X API, this project relies on **publicly available datasets** from Kaggle. The data consists of tweets referring to selected French political figures, primarily Marine Le Pen and Emmanuel Macron, with additional tweets about a male politician from a similar ideological background.\n",
    "\n",
    "Each observation includes textual content and basic interaction metadata, enabling both linguistic analysis (sentiment, toxicity, topics) and network-based analysis (reply and interaction structures). \n",
    "\n",
    "Using open datasets ensures reproducibility, transparency, and ethical compliance, while still allowing us to study real-world political discourse at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75b53ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### HERE WOULD GO ALL THE SCRAPING AND SENTIMENTAL ANALYSIS CODE ######\n",
    "## I'M NOT GOING TO INCLUDE IT NOW, AS IT'S ALREADY SAVED IN CSV FILES ##\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd5433c",
   "metadata": {},
   "source": [
    "## 5. Data Analysis Overview\n",
    "\n",
    "We use the preprocessed dataset created by our collaborator, which contains tweets mentioning Marine Le Pen, Emmanuel Macron, and a male politician from a similar ideological background.  \n",
    "\n",
    "The dataset already includes:  \n",
    "- Cleaned text  \n",
    "- Sentiment labels and scores  \n",
    "- Toxicity metrics (from Detoxify and VADER models)  \n",
    "- Metadata such as timestamp and target politician  \n",
    "\n",
    "This allows us to focus on comparing online reception between politicians without redoing the initial NLP preprocessing or scraping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6373204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (816915, 16)\n",
      "Memory(GB): 0.517965313\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>target_politician</th>\n",
       "      <th>gender</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2066830</td>\n",
       "      <td>RT @ZelenskyyUa: Continued talks with ðŸ‡«ðŸ‡· Presi...</td>\n",
       "      <td>Emmanuel Macron</td>\n",
       "      <td>M</td>\n",
       "      <td>2022-04-01 13:24:45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rt zelenskyyua continued talks president emman...</td>\n",
       "      <td>13</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.839275</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6006473</td>\n",
       "      <td>RT @LenoirSeb: Les seules excuses que @Emmanue...</td>\n",
       "      <td>Emmanuel Macron</td>\n",
       "      <td>M</td>\n",
       "      <td>2022-02-19 16:20:12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rt lenoirseb les seules excuses que emmanuelma...</td>\n",
       "      <td>19</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.975356</td>\n",
       "      <td>0.083492</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.000959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12398862</td>\n",
       "      <td>@Ambroise_Mejean @EmmanuelMacron Ridicule</td>\n",
       "      <td>Emmanuel Macron</td>\n",
       "      <td>M</td>\n",
       "      <td>2022-01-26 22:51:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ambroisemejean emmanuelmacron ridicule</td>\n",
       "      <td>3</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.993979</td>\n",
       "      <td>0.046182</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.000670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comment_id                                               text  \\\n",
       "0     2066830  RT @ZelenskyyUa: Continued talks with ðŸ‡«ðŸ‡· Presi...   \n",
       "1     6006473  RT @LenoirSeb: Les seules excuses que @Emmanue...   \n",
       "2    12398862          @Ambroise_Mejean @EmmanuelMacron Ridicule   \n",
       "\n",
       "  target_politician gender           timestamp  reply_to  \\\n",
       "0   Emmanuel Macron      M 2022-04-01 13:24:45       NaN   \n",
       "1   Emmanuel Macron      M 2022-02-19 16:20:12       NaN   \n",
       "2   Emmanuel Macron      M 2022-01-26 22:51:08       NaN   \n",
       "\n",
       "                                          clean_text  text_length sentiment  \\\n",
       "0  rt zelenskyyua continued talks president emman...           13  NEGATIVE   \n",
       "1  rt lenoirseb les seules excuses que emmanuelma...           19  NEGATIVE   \n",
       "2             ambroisemejean emmanuelmacron ridicule            3  NEGATIVE   \n",
       "\n",
       "   sentiment_score  toxicity  severe_toxicity   obscene    threat    insult  \\\n",
       "0         0.839275  0.001135         0.000103  0.000185  0.000118  0.000173   \n",
       "1         0.975356  0.083492         0.000209  0.002052  0.000563  0.002093   \n",
       "2         0.993979  0.046182         0.000160  0.000811  0.000284  0.001327   \n",
       "\n",
       "   identity_attack  \n",
       "0         0.000164  \n",
       "1         0.000959  \n",
       "2         0.000670  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "target_politician\n",
       "Emmanuel Macron    612337\n",
       "Marine Le Pen      204578\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "NEGATIVE    631935\n",
       "POSITIVE    184980\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FILE_PATH = \"le_pen_macron_twitter_2017_2022_toxicity.csv\"\n",
    "\n",
    "USE_COLS = [\n",
    "    \"comment_id\", \"text\", \"clean_text\",\n",
    "    \"target_politician\", \"gender\", \"timestamp\", \"reply_to\",\n",
    "    \"sentiment\", \"sentiment_score\",\n",
    "    \"toxicity\", \"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\",\n",
    "    \"text_length\"\n",
    "]\n",
    "\n",
    "DTYPES = {\n",
    "    \"comment_id\": \"int64\",\n",
    "    \"target_politician\": \"category\",\n",
    "    \"gender\": \"category\",\n",
    "    \"reply_to\": \"float64\",\n",
    "    \"sentiment\": \"category\",\n",
    "    \"sentiment_score\": \"float32\",\n",
    "    \"toxicity\": \"float32\",\n",
    "    \"severe_toxicity\": \"float32\",\n",
    "    \"obscene\": \"float32\",\n",
    "    \"threat\": \"float32\",\n",
    "    \"insult\": \"float32\",\n",
    "    \"identity_attack\": \"float32\",\n",
    "    \"text_length\": \"int32\",\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\n",
    "    FILE_PATH,\n",
    "    usecols=USE_COLS,\n",
    "    dtype=DTYPES,\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Memory(GB):\", df.memory_usage(deep=True).sum() / 1e9)\n",
    "\n",
    "display(df.head(3))\n",
    "display(df[\"target_politician\"].value_counts())\n",
    "display(df[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5ddaa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_politician</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>704478</th>\n",
       "      <td>Emmanuel Macron</td>\n",
       "      <td>@FlatsinMumbai @pwalla1 @EmmanuelMacron Why wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65902</th>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>RT @Qofficiel: Marine Le Pen Ã©tait sur le poin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28381</th>\n",
       "      <td>Emmanuel Macron</td>\n",
       "      <td>RT @P_Vardon: Et 8 mois plus tard, Muselier so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658157</th>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>RT @GhFlorent: ðŸ”´ AprÃ¨s Vallauris ce soir, Mari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813096</th>\n",
       "      <td>Marine Le Pen</td>\n",
       "      <td>RT @TEN_GOP: Macron's 14 points ahead, called ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       target_politician                                               text\n",
       "704478   Emmanuel Macron  @FlatsinMumbai @pwalla1 @EmmanuelMacron Why wo...\n",
       "65902      Marine Le Pen  RT @Qofficiel: Marine Le Pen Ã©tait sur le poin...\n",
       "28381    Emmanuel Macron  RT @P_Vardon: Et 8 mois plus tard, Muselier so...\n",
       "658157     Marine Le Pen  RT @GhFlorent: ðŸ”´ AprÃ¨s Vallauris ce soir, Mari...\n",
       "813096     Marine Le Pen  RT @TEN_GOP: Macron's 14 points ahead, called ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quick overview of dataset distribution for transparency\n",
    "politician_counts = df[\"target_politician\"].value_counts().reset_index()\n",
    "politician_counts.columns = [\"Politician\", \"Tweet Count\"]\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(data=politician_counts, x=\"Politician\", y=\"Tweet Count\")\n",
    "plt.title(\"Number of Tweets per Politician\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Politician\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show a few sample tweets\n",
    "display(df[[\"target_politician\", \"text\"]].sample(5, random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade039c2",
   "metadata": {},
   "source": [
    "## Robustness Checks: Sensitivity to Toxicity Thresholds\n",
    "\n",
    "Our main analyses define highly toxic tweets using a threshold of 0.30.\n",
    "To assess the robustness of our findings, we replicate key comparisons\n",
    "using alternative thresholds (0.20 and 0.50).\n",
    "\n",
    "This allows us to verify that observed differences are not driven by\n",
    "an arbitrary cutoff, but instead reflect stable patterns across\n",
    "definitions of toxicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20dcba86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'order' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m thresholds:\n\u001b[32m      5\u001b[39m     df[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtox_high_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = (df[\u001b[33m\"\u001b[39m\u001b[33mtoxicity\u001b[39m\u001b[33m\"\u001b[39m] >= t).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      6\u001b[39m     tmp = (\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         df[df[\u001b[33m\"\u001b[39m\u001b[33mtarget_politician\u001b[39m\u001b[33m\"\u001b[39m].isin(\u001b[43morder\u001b[49m)]\n\u001b[32m      8\u001b[39m         .groupby(\u001b[33m\"\u001b[39m\u001b[33mtarget_politician\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtox_high_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m]\n\u001b[32m      9\u001b[39m         .mean()\n\u001b[32m     10\u001b[39m         .reset_index()\n\u001b[32m     11\u001b[39m     )\n\u001b[32m     12\u001b[39m     tmp[\u001b[33m\"\u001b[39m\u001b[33mthreshold\u001b[39m\u001b[33m\"\u001b[39m] = t\n\u001b[32m     13\u001b[39m     robust.append(tmp)\n",
      "\u001b[31mNameError\u001b[39m: name 'order' is not defined"
     ]
    }
   ],
   "source": [
    "thresholds = [0.2, 0.3, 0.5]\n",
    "\n",
    "robust = []\n",
    "for t in thresholds:\n",
    "    df[f\"tox_high_{t}\"] = (df[\"toxicity\"] >= t).astype(int)\n",
    "    tmp = (\n",
    "        df[df[\"target_politician\"].isin(order)]\n",
    "        .groupby(\"target_politician\")[f\"tox_high_{t}\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    tmp[\"threshold\"] = t\n",
    "    robust.append(tmp)\n",
    "\n",
    "robust_df = pd.concat(robust)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.lineplot(\n",
    "    data=robust_df,\n",
    "    x=\"threshold\",\n",
    "    y=f\"tox_high_{0.3}\",\n",
    "    hue=\"target_politician\",\n",
    "    marker=\"o\"\n",
    ")\n",
    "plt.ylabel(\"Proportion of highly toxic tweets\")\n",
    "plt.title(\"Robustness to Toxicity Threshold Choice\")\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b59df5",
   "metadata": {},
   "source": [
    "## Dataset Imbalance and Its Implications\n",
    "\n",
    "The dataset is strongly unbalanced across political figures. Tweets mentioning Emmanuel\n",
    "Macron are nearly three times more frequent than those mentioning Marine Le Pen.\n",
    "\n",
    "This imbalance reflects real-world visibility differences between an incumbent president\n",
    "and an opposition leader, but it also has important methodological implications.\n",
    "In particular, large sample sizes can inflate statistical significance, making even very\n",
    "small differences appear meaningful.\n",
    "\n",
    "For this reason, the analysis will consistently emphasize:\n",
    "- Effect sizes rather than p-values alone,\n",
    "- Confidence intervals,\n",
    "- Visual inspection of distributions,\n",
    "- And, when relevant, balanced subsampling for visualization purposes.\n",
    "\n",
    "As a result, statistical significance is interpreted cautiously throughout the analysis,\n",
    "with emphasis placed on robustness and consistency rather than absolute differences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce13318",
   "metadata": {},
   "source": [
    "The distribution shows that the dataset is strongly unbalanced across political figures. Tweets mentioning Emmanuel Macron (612,337) are almost three times more frequent than those mentioning Marine Le Pen (204,578). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124f5b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"is_negative\"] = (df[\"sentiment\"] == \"NEGATIVE\").astype(\"int8\")\n",
    "\n",
    "df[\"tox_high_03\"] = (df[\"toxicity\"] >= 0.30).astype(\"int8\")\n",
    "df[\"tox_high_05\"] = (df[\"toxicity\"] >= 0.50).astype(\"int8\")\n",
    "\n",
    "df[\"is_retweet\"] = df[\"text\"].astype(str).str.startswith(\"RT\").astype(\"int8\")\n",
    "\n",
    "df[\"month\"] = df[\"timestamp\"].dt.to_period(\"M\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "palette = {\n",
    "    'Emmanuel Macron': '#1f77b4',   # azul\n",
    "    'Marine Le Pen': '#0b1c2d'       # azul oscuro\n",
    "}\n",
    "\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',        # o 'sans-serif'\n",
    "    'font.serif': ['Times New Roman'],  # o 'DejaVu Serif'\n",
    "    'axes.titlesize': 13,\n",
    "    'axes.titleweight': 'bold',\n",
    "    'axes.labelsize': 11,\n",
    "    'axes.labelweight': 'regular',\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'figure.titlesize': 14\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa253b39",
   "metadata": {},
   "source": [
    "## Hypothesis 1: Negativity and Toxicity\n",
    "\n",
    "Our first hypothesis states that tweets referring to Marine Le Pen exhibit higher levels\n",
    "of negativity and toxicity than those referring to Emmanuel Macron.\n",
    "\n",
    "We begin by analyzing **overall sentiment polarity**, focusing on the proportion of tweets\n",
    "classified as negative. This provides a high-level measure of online hostility and allows\n",
    "us to situate both politicians within the broader context of political discourse on Twitter.\n",
    "\n",
    "These findings partially support Hypothesis 1: while Marine Le Pen is consistently exposed\n",
    "to higher negativity, the substantive magnitude of toxicity differences remains limited.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b88ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_prop = (\n",
    "    df.groupby(\"target_politician\")[\"is_negative\"]\n",
    "      .mean()\n",
    "      .reset_index(name=\"neg_rate\")\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=False)\n",
    "\n",
    "# --- GrÃ¡fico 1: eje truncado (zoom) ---\n",
    "sns.barplot(\n",
    "    data=neg_prop,\n",
    "    x=\"target_politician\",\n",
    "    y=\"neg_rate\",\n",
    "    palette=palette,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_ylim(0.70, 0.85)\n",
    "axes[0].set_title(\"Zoom on proportions\")\n",
    "axes[0].set_ylabel(\"Proportion of negative tweets\")\n",
    "axes[0].set_xlabel(\"Politician\")\n",
    "\n",
    "# --- GrÃ¡fico 2: escala completa (0 a 1) ---\n",
    "sns.barplot(\n",
    "    data=neg_prop,\n",
    "    x=\"target_politician\",\n",
    "    y=\"neg_rate\",\n",
    "    palette=palette,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].set_title(\"Full scale (0â€“1)\")\n",
    "axes[1].set_ylabel(\"Proportion of negative tweets\")\n",
    "axes[1].set_xlabel(\"Politician\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Proportion of Negative Tweets by Politician\\n\"\n",
    "    \"Left: truncated y-axis | Right: full y-axis\",\n",
    "    fontsize=11\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1038ad7",
   "metadata": {},
   "source": [
    "**Interpreting Proportions in a High-Negativity Environment**\n",
    "\n",
    "It is important to interpret these results in context. Twitter political discourse is\n",
    "characterized by a high baseline of negativity, often described in the literature as a\n",
    "â€œnegativity biasâ€ or â€œnegativity floorâ€.\n",
    "\n",
    "Within this environment, differences of a few percentage points may appear small in absolute\n",
    "terms, yet they can still reflect systematic disparities in how political figures are treated.\n",
    "The consistent gap observed between Macron and Le Pen therefore motivates a more formal\n",
    "statistical evaluation of the difference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd63059",
   "metadata": {},
   "source": [
    "### From Visualization to Statistical Inference\n",
    "\n",
    "Visual differences alone are insufficient to determine whether observed gaps reflect\n",
    "systematic patterns or random variation.\n",
    "\n",
    "We therefore complement the descriptive analysis with:\n",
    "- Ï‡Â² tests for differences in proportions,\n",
    "- Effect size estimates (CramÃ©râ€™s V),\n",
    "- Distributional comparisons using the Mannâ€“Whitney test,\n",
    "- And bootstrap confidence intervals to quantify uncertainty.\n",
    "\n",
    "This multi-pronged approach allows us to distinguish statistical significance from\n",
    "substantive relevance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3df663",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = \"Emmanuel Macron\"\n",
    "B = \"Marine Le Pen\"\n",
    "\n",
    "df_ml = df[df[\"target_politician\"].isin([A, B])].copy()\n",
    "\n",
    "def cramers_v_from_table(table):\n",
    "    chi2, p, dof, expected = chi2_contingency(table)\n",
    "    n = table.to_numpy().sum()\n",
    "    v = np.sqrt(chi2 / (n * (min(table.shape) - 1)))\n",
    "    return chi2, p, dof, v\n",
    "\n",
    "def bootstrap_diff(x, y, stat=\"mean\", n_boot=2000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    f = np.mean if stat == \"mean\" else np.median\n",
    "    diffs = np.empty(n_boot, dtype=np.float64)\n",
    "\n",
    "    for i in range(n_boot):\n",
    "        xs = rng.choice(x, size=len(x), replace=True)\n",
    "        ys = rng.choice(y, size=len(y), replace=True)\n",
    "        diffs[i] = f(xs) - f(ys)\n",
    "\n",
    "    return np.percentile(diffs, [2.5, 50, 97.5])\n",
    "\n",
    "# --- Ï‡Â²: proporciÃ³n de negativos ---\n",
    "tab_neg = pd.crosstab(df_ml[\"target_politician\"], df_ml[\"is_negative\"])\n",
    "chi2, p, dof, v = cramers_v_from_table(tab_neg)\n",
    "print(\"Ï‡Â² (is_negative) contingency:\\n\", tab_neg)\n",
    "print(f\"Chi2={chi2:.2f}, p={p:.4e}, CramÃ©r's V={v:.4f}\")\n",
    "\n",
    "# --- Ï‡Â²: toxicidad alta (0.30) ---\n",
    "tab_tox = pd.crosstab(df_ml[\"target_politician\"], df_ml[\"tox_high_03\"])\n",
    "chi2, p, dof, v = cramers_v_from_table(tab_tox)\n",
    "print(\"\\nÏ‡Â² (tox_high_03) contingency:\\n\", tab_tox)\n",
    "print(f\"Chi2={chi2:.2f}, p={p:.4e}, CramÃ©r's V={v:.4f}\")\n",
    "\n",
    "# --- Mannâ€“Whitney: toxicidad continua ---\n",
    "tox_A = df_ml.loc[df_ml[\"target_politician\"] == A, \"toxicity\"].dropna()\n",
    "tox_B = df_ml.loc[df_ml[\"target_politician\"] == B, \"toxicity\"].dropna()\n",
    "u, p_mw = mannwhitneyu(tox_A, tox_B, alternative=\"two-sided\")\n",
    "print(f\"\\nMannâ€“Whitney toxicity: U={u:.2e}, p={p_mw:.4e}\")\n",
    "\n",
    "# --- Bootstrap: diferencia (A - B) ---\n",
    "ci_mean = bootstrap_diff(tox_A, tox_B, stat=\"mean\")\n",
    "ci_med  = bootstrap_diff(tox_A, tox_B, stat=\"median\")\n",
    "print(\"Bootstrap CI mean(A-B) [2.5,50,97.5] =\", ci_mean)\n",
    "print(\"Bootstrap CI med(A-B)  [2.5,50,97.5] =\", ci_med)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c55dc0",
   "metadata": {},
   "source": [
    "The statistical tests confirm systematic differences in the online reception of Emmanuel Macron and Marine Le Pen.\n",
    "\n",
    "A $\\chi^2$ test on the proportion of negative tweets shows a very strong statistical difference ($p < 0.001$), with tweets about Marine Le Pen being more frequently negative. However, the effect size is small (CramÃ©râ€™s $V \\approx 0.061$), indicating a limited substantive magnitude despite high significance.\n",
    "\n",
    "Differences in highly toxic tweets (toxicity $\\geq 0.30$) are also statistically significant ($p \\approx 0.0037$) but practically negligible (CramÃ©râ€™s $V \\approx 0.003$). Consistently, a Mannâ€“Whitney test on the full toxicity distribution finds that tweets about Le Pen are on average slightly more toxic than those about Macron, although the magnitude of this difference is very small.\n",
    "\n",
    "Overall, Marine Le Pen receives a more negative and marginally more toxic online reception than Emmanuel Macron. Importantly, these results illustrate that with very large datasets, statistical significance must be interpreted alongside effect sizes and confidence intervals rather than $p$-values alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7461b6e3",
   "metadata": {},
   "source": [
    "### Summary of H1 analysis:\n",
    "\n",
    "The analysis provides consistent evidence that Marine Le Pen receives a more negative and\n",
    "slightly more toxic online reception than Emmanuel Macron.\n",
    "\n",
    "However, effect sizes remain small, highlighting a key challenge of computational social\n",
    "science: large datasets make it easy to detect statistically significant differences that\n",
    "are substantively modest.\n",
    "\n",
    "These results suggest that while differences exist, they cannot be interpreted in isolation.\n",
    "The next step is therefore to examine **how** toxicity manifests, rather than only **how much**\n",
    "of it is present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b6b7a",
   "metadata": {},
   "source": [
    "# Toxicity distribution (violin + box) by politician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [\"Emmanuel Macron\", \"Marine Le Pen\"]  # ajusta si agregas mÃ¡s\n",
    "\n",
    "# Para exportar\n",
    "FIG_DIR = \"figures\"\n",
    "import os\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "ax = sns.violinplot(\n",
    "    data=df[df[\"target_politician\"].isin(order)],\n",
    "    x=\"target_politician\", y=\"toxicity\",\n",
    "    order=order,\n",
    "    inner=None, cut=0\n",
    ")\n",
    "sns.boxplot(\n",
    "    data=df[df[\"target_politician\"].isin(order)],\n",
    "    x=\"target_politician\", y=\"toxicity\",\n",
    "    order=order,\n",
    "    width=0.25, showfliers=False,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Toxicity score (0â€“1)\")\n",
    "ax.set_title(\"Toxicity distribution by politician\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/toxicity_violin_box.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0187a6d7",
   "metadata": {},
   "source": [
    "### Distributional Differences in Toxicity\n",
    "\n",
    "While boxplots summarize central tendencies and dispersion, they may obscure\n",
    "differences in the shape of the distributions.  \n",
    "To further explore how toxicity is distributed across tweets, we plot kernel\n",
    "density estimates for each political figure.\n",
    "\n",
    "This visualization highlights differences in the tails of the distributions,\n",
    "which are particularly relevant when studying extreme or highly toxic content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for pol in order:\n",
    "    sns.kdeplot(\n",
    "        data=df[df[\"target_politician\"] == pol],\n",
    "        x=\"toxicity\",\n",
    "        fill=True,\n",
    "        alpha=0.4,\n",
    "        label=pol\n",
    "    )\n",
    "\n",
    "plt.title(\"Density of Toxicity Scores by Politician\")\n",
    "plt.xlabel(\"Toxicity score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend(frameon=False)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3acf5a",
   "metadata": {},
   "source": [
    "Although average toxicity levels differ only modestly, tweets referring to Marine Le Pen exhibit a slightly heavier right tail, indicating a higher prevalence of extreme toxic expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000bc55",
   "metadata": {},
   "source": [
    "## Beyond Aggregate Toxicity\n",
    "\n",
    "Overall toxicity scores may mask important qualitative differences in the nature of online\n",
    "attacks. Toxic language can take many forms, ranging from general insults to identity-based\n",
    "attacks.\n",
    "\n",
    "To explore whether Marine Le Pen and Emmanuel Macron are targeted in different ways, we now\n",
    "compare specific toxicity dimensions produced by the classification model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b63a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ComparaciÃ³n de mÃ©tricas especÃ­ficas\n",
    "metrics = ['toxicity', 'obscene', 'insult', 'identity_attack']\n",
    "detailed = df.groupby('target_politician')[metrics].mean().melt(ignore_index=False).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=detailed, x='variable', y='value', hue='target_politician', palette=palette)\n",
    "plt.title(\"Toxicity Profiles: Beyond general negativity\")\n",
    "plt.ylabel(\"Average Score\")\n",
    "plt.xlabel(\"Category\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2cc19",
   "metadata": {},
   "source": [
    "While differences across specific toxicity dimensions are relatively small, the profiles\n",
    "suggest that tweets about Marine Le Pen tend to score slightly higher on personal and\n",
    "identity-related categories.\n",
    "\n",
    "This pattern is consistent with prior literature suggesting that female politicians are\n",
    "more frequently targeted through personalized or delegitimizing language, even when overall\n",
    "toxicity levels are comparable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319cb83",
   "metadata": {},
   "source": [
    "### Composition of Toxicity at Different Intensity Levels\n",
    "\n",
    "Aggregate averages may conceal how toxic language escalates.\n",
    "We therefore compare the composition of toxic speech at low versus high toxicity levels,\n",
    "focusing on insults and identity-based attacks.\n",
    "\n",
    "This helps distinguish between general hostility and more targeted or delegitimizing forms\n",
    "of discourse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define low vs high toxicity\n",
    "df['tox_bin'] = pd.cut(\n",
    "    df['toxicity'],\n",
    "    bins=[0, 0.3, 1],\n",
    "    labels=['low', 'high']\n",
    ")\n",
    "\n",
    "comp = (\n",
    "    df[df['target_politician'].isin(order)]\n",
    "    .groupby(['target_politician', 'tox_bin'])[['insult', 'identity_attack']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "comp\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(\n",
    "    data=comp,\n",
    "    x='tox_bin',\n",
    "    y='identity_attack',\n",
    "    hue='target_politician',\n",
    "    palette=palette\n",
    ")\n",
    "plt.title(\"Identity Attacks by Toxicity Level\")\n",
    "plt.xlabel(\"Toxicity level\")\n",
    "plt.ylabel(\"Average identity attack score\")\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3aed9f",
   "metadata": {},
   "source": [
    "## Temporal Dynamics of Online Reception\n",
    "\n",
    "Aggregate statistics may conceal important temporal variations driven by political events,\n",
    "campaign periods, or media controversies.\n",
    "\n",
    "We therefore examine the evolution of negativity and toxicity over time, using monthly\n",
    "aggregations and confidence intervals. This allows us to assess whether observed differences\n",
    "are persistent or event-driven.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aseguramos que la columna month sea tratada como fecha\n",
    "if \"month\" not in df.columns:\n",
    "    df[\"month\"] = pd.to_datetime(df[\"timestamp\"]).dt.to_period(\"M\").astype(str)\n",
    "\n",
    "monthly = (\n",
    "    df[df[\"target_politician\"].isin(order)]\n",
    "      .groupby([\"month\",\"target_politician\"])\n",
    "      .agg(\n",
    "          n=(\"comment_id\", \"count\"),\n",
    "          neg_rate=(\"is_negative\", \"mean\"),\n",
    "          tox_high=(\"tox_high_03\", \"mean\"),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "monthly[\"month_date\"] = pd.to_datetime(monthly[\"month\"] + \"-01\")\n",
    "\n",
    "# CÃ¡lculo de bandas de error (95% CI)\n",
    "z = 1.96\n",
    "monthly[\"neg_se\"] = np.sqrt(monthly[\"neg_rate\"]*(1-monthly[\"neg_rate\"]) / monthly[\"n\"])\n",
    "monthly[\"neg_low\"] = (monthly[\"neg_rate\"] - z*monthly[\"neg_se\"]).clip(0,1)\n",
    "monthly[\"neg_high\"] = (monthly[\"neg_rate\"] + z*monthly[\"neg_se\"]).clip(0,1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for pol in order:\n",
    "    sub = monthly[monthly[\"target_politician\"] == pol].sort_values(\"month_date\")\n",
    "    plt.plot(sub[\"month_date\"], sub[\"neg_rate\"], label=pol, lw=2)\n",
    "    plt.fill_between(sub[\"month_date\"], sub[\"neg_low\"], sub[\"neg_high\"], alpha=0.15)\n",
    "\n",
    "plt.title(\"Evolution of Negative Sentiment (95% Confidence Intervals)\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"Negative Rate\")\n",
    "plt.legend(frameon=False)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f32394",
   "metadata": {},
   "source": [
    "### Temporal Patterns in Toxicity Intensity\n",
    "\n",
    "Beyond overall temporal trends, it is informative to examine how toxicity varies\n",
    "jointly across time and political figures.\n",
    "\n",
    "We therefore visualize average monthly toxicity using a heatmap, which allows us\n",
    "to identify periods of heightened hostility and assess whether these affect\n",
    "politicians differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da37328",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat = (\n",
    "    df[df[\"target_politician\"].isin(order)]\n",
    "    .groupby([\"month\", \"target_politician\"])[\"toxicity\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "heat_pivot = heat.pivot(\n",
    "    index=\"month\",\n",
    "    columns=\"target_politician\",\n",
    "    values=\"toxicity\"\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(\n",
    "    heat_pivot,\n",
    "    cmap=\"Reds\",\n",
    "    linewidths=0.3\n",
    ")\n",
    "plt.title(\"Average Toxicity Over Time\")\n",
    "plt.xlabel(\"Politician\")\n",
    "plt.ylabel(\"Month\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def2493",
   "metadata": {},
   "source": [
    "Periods of increased toxicity tend to affect Marine Le Pen more strongly, although both figures follow similar temporal patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b905e39",
   "metadata": {},
   "source": [
    "### Interaction Context: Replies vs Standalone Tweets\n",
    "\n",
    "Online hostility may be shaped by interaction dynamics.\n",
    "Replies often involve direct confrontation, whereas standalone tweets may reflect broader\n",
    "commentary.\n",
    "\n",
    "We compare toxicity levels in replies versus non-replies to assess whether gendered\n",
    "differences are amplified in direct interactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_reply'] = df['reply_to'].notna().astype(int)\n",
    "\n",
    "reply_stats = (\n",
    "    df[df['target_politician'].isin(order)]\n",
    "    .groupby(['target_politician', 'is_reply'])['toxicity']\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "reply_stats\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.barplot(\n",
    "    data=reply_stats,\n",
    "    x='is_reply',\n",
    "    y='toxicity',\n",
    "    hue='target_politician',\n",
    "    palette=palette\n",
    ")\n",
    "plt.xticks([0,1], ['Standalone tweet', 'Reply'])\n",
    "plt.ylabel(\"Average toxicity\")\n",
    "plt.title(\"Toxicity in Replies vs Standalone Tweets\")\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf563eb5",
   "metadata": {},
   "source": [
    "### Stability of the Negativity Gap\n",
    "\n",
    "The difference-in-differences visualization highlights periods where the negativity gap\n",
    "widens or narrows, but it remains predominantly positive over time.\n",
    "\n",
    "This suggests that the higher negativity toward Marine Le Pen is not driven by isolated\n",
    "events alone, but reflects a more stable pattern of online reception.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401d8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_diff(monthly, metric, pol1, pol2):\n",
    "    piv = monthly.pivot(index=\"month_date\", columns=\"target_politician\", values=metric)\n",
    "    return (piv[pol2] - piv[pol1]).dropna()\n",
    "\n",
    "diff_neg = pivot_diff(monthly, \"neg_rate\", \"Emmanuel Macron\", \"Marine Le Pen\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(diff_neg.index, diff_neg.values, color='black', lw=1.5)\n",
    "plt.axhline(0, color='red', linestyle='--', alpha=0.6) # LÃ­nea de igualdad\n",
    "\n",
    "# Rellenar para enfatizar quiÃ©n recibe mÃ¡s negatividad\n",
    "plt.fill_between(diff_neg.index, 0, diff_neg.values, \n",
    "                 where=(diff_neg.values > 0), color='gray', alpha=0.3, label=\"More negative towards Le Pen\")\n",
    "\n",
    "plt.title(\"Negativity Gap (Le Pen vs Macron)\", fontsize=14, fontweight='bold')\n",
    "plt.ylabel(\"Î” Negative Rate\")\n",
    "plt.legend(loc='upper left', frameon = False)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ccc29d",
   "metadata": {},
   "source": [
    "This figure compares the distribution of sentiment scores for tweets mentioning Emmanuel Macron and Marine Le Pen, shown both with and without outliers.\n",
    "\n",
    "In both panels, sentiment scores are generally high (close to 1), which is consistent with the fact that the sentiment_score represents the modelâ€™s confidence in its prediction rather than a signed polarity scale. The medians for both politicians are very similar, indicating that when tweets are classified as positive or negative, the model is typically quite confident in its decision for both cases.\n",
    "\n",
    "When outliers are included (left panel), both distributions show a noticeable tail toward lower scores (around 0.5â€“0.6), corresponding to tweets for which the classifier is less confident. Marine Le Pen exhibits slightly more low-confidence observations, suggesting a somewhat broader dispersion in how clearly tweets about her are classified in terms of sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc04059",
   "metadata": {},
   "source": [
    "## Hypothesis 2: Personalization and Expressive Effort\n",
    "\n",
    "Our second hypothesis concerns the nature of discourse rather than its tone.\n",
    "If tweets targeting Marine Le Pen are more personalized or gendered, one might expect them\n",
    "to be longer or more elaborated.\n",
    "\n",
    "As a first proxy for personalization, we analyze tweet length as an indicator of expressive\n",
    "effort.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f74dc0b",
   "metadata": {},
   "source": [
    "### Toxicity and Personalization: Are Longer Tweets More Hostile?\n",
    "\n",
    "If personalized or gendered attacks require more expressive effort, we would expect\n",
    "toxicity to increase with tweet length.\n",
    "\n",
    "We therefore examine the relationship between tweet length and toxicity, both overall\n",
    "and separately by politician. This allows us to assess whether personalization is\n",
    "associated with more hostile language, and whether this relationship differs across\n",
    "political figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3284dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between tweet length and toxicity\n",
    "corr_all = df[['text_length', 'toxicity']].corr().iloc[0,1]\n",
    "print(f\"Overall correlation (length ~ toxicity): {corr_all:.3f}\")\n",
    "\n",
    "# Correlation by politician\n",
    "corr_by_pol = (\n",
    "    df.groupby('target_politician')[['text_length', 'toxicity']]\n",
    "      .corr()\n",
    "      .iloc[0::2, -1]\n",
    "      .reset_index()\n",
    "      .rename(columns={'toxicity': 'corr_length_toxicity'})\n",
    ")\n",
    "\n",
    "corr_by_pol\n",
    "\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.regplot(\n",
    "    data=df[df['target_politician'].isin(order)],\n",
    "    x='text_length',\n",
    "    y='toxicity',\n",
    "    scatter_kws={'alpha':0.05},\n",
    "    line_kws={'color':'black'}\n",
    ")\n",
    "plt.title(\"Relationship between Tweet Length and Toxicity\")\n",
    "plt.xlabel(\"Tweet length (characters)\")\n",
    "plt.ylabel(\"Toxicity score\")\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0dd1c5",
   "metadata": {},
   "source": [
    "### Structure of Toxic Language\n",
    "\n",
    "Aggregate toxicity scores may conflate different forms of hostility.\n",
    "To better understand how toxic expressions are structured, we examine the\n",
    "relationship between general insults and identity-based attacks.\n",
    "\n",
    "This representation allows us to assess whether comparable levels of insult are\n",
    "associated with different degrees of identity targeting across politicians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c30b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = (\n",
    "    df[df[\"target_politician\"].isin(order)]\n",
    "    .sample(15000, random_state=42)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.scatterplot(\n",
    "    data=sample,\n",
    "    x=\"insult\",\n",
    "    y=\"identity_attack\",\n",
    "    hue=\"target_politician\",\n",
    "    alpha=0.3,\n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "plt.title(\"Structure of Toxic Language\")\n",
    "plt.xlabel(\"Insult score\")\n",
    "plt.ylabel(\"Identity attack score\")\n",
    "sns.despine()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec2c4a",
   "metadata": {},
   "source": [
    "At comparable levels of general insult, tweets referring to Marine Le Pen tend\n",
    "to score slightly higher on identity-based attacks, suggesting a more\n",
    "personalized form of hostility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05ce84",
   "metadata": {},
   "source": [
    "### Synthesis of Findings\n",
    "\n",
    "Across multiple analytical dimensions, the results converge on a consistent pattern.\n",
    "Tweets referring to Marine Le Pen are not only more negative on average, but also differ in\n",
    "how hostility is expressed.\n",
    "\n",
    "Toxic language directed at Le Pen tends to be slightly more personalized, more identity-\n",
    "oriented at higher toxicity levels, and more pronounced in direct interaction contexts.\n",
    "While these differences remain modest in magnitude, their stability across methods,\n",
    "metrics, and time suggests that they reflect systematic features of online political\n",
    "discourse rather than isolated events.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6f362",
   "metadata": {},
   "source": [
    "## From Description to Interpretation\n",
    "\n",
    "Taken together, the analyses suggest that Marine Le Pen is subject to a consistently more\n",
    "negative and marginally more toxic online reception than Emmanuel Macron.\n",
    "\n",
    "At the same time, the magnitude of these differences remains limited, pointing to the\n",
    "importance of political context and platform-wide norms of negativity.\n",
    "\n",
    "The following conclusion situates these findings within the broader literature on gender,\n",
    "political communication, and computational social science, while discussing limitations\n",
    "and directions for future research.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9929f656",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'order' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Synthesis: key metrics per politician\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m summary_metrics = df[df[\u001b[33m\"\u001b[39m\u001b[33mtarget_politician\u001b[39m\u001b[33m\"\u001b[39m].isin(\u001b[43morder\u001b[49m)].groupby(\u001b[33m\"\u001b[39m\u001b[33mtarget_politician\u001b[39m\u001b[33m\"\u001b[39m).agg(\n\u001b[32m      3\u001b[39m     n_tweets=(\u001b[33m\"\u001b[39m\u001b[33mcomment_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      4\u001b[39m     neg_rate=(\u001b[33m\"\u001b[39m\u001b[33mis_negative\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      5\u001b[39m     mean_toxicity=(\u001b[33m\"\u001b[39m\u001b[33mtoxicity\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      6\u001b[39m     median_toxicity=(\u001b[33m\"\u001b[39m\u001b[33mtoxicity\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      7\u001b[39m     mean_identity=(\u001b[33m\"\u001b[39m\u001b[33midentity_attack\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      8\u001b[39m     mean_insult=(\u001b[33m\"\u001b[39m\u001b[33minsult\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      9\u001b[39m     avg_length=(\u001b[33m\"\u001b[39m\u001b[33mtext_length\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m ).reset_index()\n\u001b[32m     12\u001b[39m display(summary_metrics)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Optional: barplot of main results for presentation-ready visualization\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'order' is not defined"
     ]
    }
   ],
   "source": [
    "# Synthesis: key metrics per politician\n",
    "summary_metrics = df[df[\"target_politician\"].isin(order)].groupby(\"target_politician\").agg(\n",
    "    n_tweets=(\"comment_id\", \"count\"),\n",
    "    neg_rate=(\"is_negative\", \"mean\"),\n",
    "    mean_toxicity=(\"toxicity\", \"mean\"),\n",
    "    median_toxicity=(\"toxicity\", \"median\"),\n",
    "    mean_identity=(\"identity_attack\", \"mean\"),\n",
    "    mean_insult=(\"insult\", \"mean\"),\n",
    "    avg_length=(\"text_length\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "display(summary_metrics)\n",
    "\n",
    "# Optional: barplot of main results for presentation-ready visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,8))\n",
    "\n",
    "sns.barplot(data=summary_metrics, x=\"target_politician\", y=\"neg_rate\", palette=palette, ax=axes[0,0])\n",
    "axes[0,0].set_title(\"Proportion Negative Tweets\")\n",
    "\n",
    "sns.barplot(data=summary_metrics, x=\"target_politician\", y=\"mean_toxicity\", palette=palette, ax=axes[0,1])\n",
    "axes[0,1].set_title(\"Mean Toxicity\")\n",
    "\n",
    "sns.barplot(data=summary_metrics, x=\"target_politician\", y=\"mean_identity\", palette=palette, ax=axes[1,0])\n",
    "axes[1,0].set_title(\"Mean Identity Attack\")\n",
    "\n",
    "sns.barplot(data=summary_metrics, x=\"target_politician\", y=\"mean_insult\", palette=palette, ax=axes[1,1])\n",
    "axes[1,1].set_title(\"Mean Insult\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_xlabel(\"Politician\")\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f20a046",
   "metadata": {},
   "source": [
    "## Key Takeaways by Hypothesis\n",
    "\n",
    "**H1: Negativity & Toxicity**\n",
    "- Marine Le Pen consistently receives slightly more negative and toxic tweets than Emmanuel Macron.\n",
    "- Effect sizes are small but persistent across metrics and time.\n",
    "\n",
    "**H2: Personalization & Expressive Effort**\n",
    "- Tweets about Le Pen show marginally higher identity-based attacks and insults.\n",
    "- Longer tweets tend to be slightly more toxic, suggesting more expressive effort in personalized attacks.\n",
    "\n",
    "**Temporal & Interaction Dynamics**\n",
    "- The negativity gap remains relatively stable over time.\n",
    "- Replies tend to be more toxic than standalone tweets, with small gendered differences.\n",
    "\n",
    "**Limitations**\n",
    "- Dataset limited to Twitter; results may not generalize offline.\n",
    "- NLP models carry inherent biases; toxicity scores are probabilistic.\n",
    "- Gender and political alignment are confounded; causal inference is not possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5f67b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This study examined gendered patterns in online political reception using\n",
    "large-scale Twitter data and computational methods.\n",
    "\n",
    "We find that Marine Le Pen is consistently exposed to a more negative and slightly\n",
    "more toxic online reception than Emmanuel Macron. While these differences are\n",
    "modest in magnitude, they are stable across time, toxicity dimensions, and\n",
    "interaction contexts.\n",
    "\n",
    "Importantly, comparisons with a male politician from a similar ideological\n",
    "background suggest that political alignment explains partâ€”but not allâ€”of the\n",
    "observed gap.\n",
    "\n",
    "Taken together, these findings highlight the value of combining quantitative\n",
    "scale with interpretive caution. Computational methods allow us to detect\n",
    "systematic patterns in online discourse, but understanding their meaning\n",
    "requires careful attention to context, limitations, and ethical responsibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b825b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fin\n",
    "# from here it is only brouillons / drafts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c4242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd02743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435a08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef5b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e7644",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df.columns = df.columns.astype(str).str.strip()\n",
    "\n",
    "# Ver columnas que podrÃ­an ser el polÃ­tico\n",
    "candidates = [c for c in df.columns if (\"polit\" in c.lower()) or (\"macron\" in c.lower()) or (\"le\" in c.lower()) or (\"target\" in c.lower()) or (\"name\" in c.lower())]\n",
    "print(\"Candidates:\", candidates)\n",
    "\n",
    "# Ver todas las columnas por si no aparece en candidates\n",
    "print(\"All columns:\")\n",
    "for c in df.columns:\n",
    "    print(\" -\", c)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35930949",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def sample_per_group(df, group_col, n=20000, seed=42):\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.astype(str).str.strip()\n",
    "\n",
    "    # Si la columna estÃ¡ en el Ã­ndice, la devolvemos a columnas\n",
    "    if group_col not in df.columns and group_col in df.index.names:\n",
    "        df = df.reset_index()\n",
    "\n",
    "    if group_col not in df.columns:\n",
    "        raise KeyError(f\"'{group_col}' no estÃ¡ en df.columns. Columnas: {list(df.columns)}\")\n",
    "\n",
    "    parts = []\n",
    "    # sort=False para mantener orden original; random_state fijo para reproducibilidad\n",
    "    for _, g in df.groupby(group_col, sort=False):\n",
    "        k = min(len(g), n)\n",
    "        parts.append(g.sample(n=k, random_state=seed))\n",
    "\n",
    "    out = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "    # GarantÃ­a\n",
    "    if group_col not in out.columns:\n",
    "        raise KeyError(f\"DespuÃ©s del muestreo, '{group_col}' no estÃ¡. Columnas: {list(out.columns)}\")\n",
    "\n",
    "    return out'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d0d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''print(\"df_plot type:\", type(df_plot))\n",
    "print(\"df_plot columns:\", list(df_plot.columns))\n",
    "print(\"df_plot index names:\", df_plot.index.names)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df_plot = sample_per_group(df, \"target_politician\", n=20000)\n",
    "\n",
    "print(\"df_plot columns:\", list(df_plot.columns))\n",
    "print(df_plot[[\"target_politician\", \"sentiment_score\"]].head())\n",
    "\n",
    "order = df_plot[\"target_politician\"].value_counts().index.tolist()\n",
    "\n",
    "plt.figure(figsize=(11, 5))\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "ax = sns.stripplot(\n",
    "    data=df_plot,\n",
    "    x=\"sentiment_score\",\n",
    "    y=\"target_politician\",\n",
    "    hue=\"target_politician\",\n",
    "    order=order,\n",
    "    palette=palette,\n",
    "    size=4,\n",
    "    alpha=0.7,\n",
    "    jitter=True,\n",
    "    orient=\"h\"\n",
    ")\n",
    "\n",
    "means = df.groupby(\"target_politician\")[\"sentiment_score\"].mean()\n",
    "\n",
    "for i, politician in enumerate(order):\n",
    "    avg = float(means.loc[politician])\n",
    "    plt.vlines(avg, i - 0.2, i + 0.2,\n",
    "               color=\"red\", linestyle=\"--\", lw=2,\n",
    "               label=\"Promedio\" if i == 0 else \"\")\n",
    "\n",
    "plt.title(\"Public Sentiment Pulse\\n\", fontsize=16, fontweight=\"bold\", loc=\"left\")\n",
    "plt.xlabel(\"Sentiment Score (0 = Negative | 1 = Positive)\", fontsize=10, color=\"gray\")\n",
    "plt.ylabel(\"\")\n",
    "plt.legend(title=\"Politician\", bbox_to_anchor=(1, 1), frameon=False)\n",
    "sns.despine(left=True, bottom=False)\n",
    "plt.tight_layout()\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6940f04",
   "metadata": {},
   "source": [
    "Emmanuel Macron and Marine Le Pen, based on a balanced subsample of the data.\n",
    "\n",
    "Each point represents an individual tweet, and the horizontal spread shows the sentiment score assigned by the classifier (from 0 = negative to 1 = positive). For both politicians, the scores are heavily concentrated toward higher values, indicating that when the model assigns a sentiment label, it typically does so with high confidence. This is consistent with the boxplot results and reflects properties of the sentiment model rather than strongly positive public opinion.\n",
    "\n",
    "The dashed red vertical lines indicate the average sentiment score for each politician. These averages are very close to one another, suggesting that the confidence of sentiment classification is similar for tweets about Emmanuel Macron and Marine Le Pen. In other words, the model is not systematically more uncertain when classifying tweets about one politician versus the other.\n",
    "\n",
    "At the same time, the visual density differs slightly across the lower end of the scale: tweets about Marine Le Pen show a marginally thicker tail of lower sentiment scores, which is consistent with the presence of more ambiguous or borderline cases. However, this difference is subtle and does not dominate the overall distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c7096",
   "metadata": {},
   "source": [
    "# Bars with IC bootstrap (proportion of negatives and tox_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab0ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def bootstrap_ci_mean(x, n_boot=2000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = np.asarray(x)\n",
    "    boots = rng.choice(x, size=(n_boot, len(x)), replace=True).mean(axis=1)\n",
    "    return np.percentile(boots, [2.5, 50, 97.5])\n",
    "\n",
    "def bootstrap_ci_prop(x, n_boot=2000, seed=42):\n",
    "    # x debe ser 0/1\n",
    "    return bootstrap_ci_mean(x, n_boot=n_boot, seed=seed)\n",
    "\n",
    "def summarize_ci(df, group_col, value_col, func_ci):\n",
    "    rows = []\n",
    "    for g, sub in df.groupby(group_col):\n",
    "        ci = func_ci(sub[value_col].dropna().values)\n",
    "        rows.append({\n",
    "            group_col: g,\n",
    "            \"low\": ci[0],\n",
    "            \"mid\": ci[1],\n",
    "            \"high\": ci[2],\n",
    "            \"n\": len(sub)\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3d600a",
   "metadata": {},
   "source": [
    "## Proportion of negatives (CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27daac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df_sub = df[df[\"target_politician\"].isin(order)].copy()\n",
    "\n",
    "neg_ci = summarize_ci(df_sub, \"target_politician\", \"is_negative\", bootstrap_ci_prop)\n",
    "neg_ci[\"err_low\"] = neg_ci[\"mid\"] - neg_ci[\"low\"]\n",
    "neg_ci[\"err_high\"] = neg_ci[\"high\"] - neg_ci[\"mid\"]\n",
    "\n",
    "neg_ci = neg_ci.set_index(\"target_politician\").loc[order].reset_index()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "ax = plt.gca()\n",
    "ax.bar(\n",
    "    neg_ci[\"target_politician\"],\n",
    "    neg_ci[\"mid\"],\n",
    "    yerr=[neg_ci[\"err_low\"], neg_ci[\"err_high\"]],\n",
    "    capsize=6\n",
    ")\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Proportion negative (bootstrap 95% CI)\")\n",
    "ax.set_title(\"Negative tweets by politician\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/neg_rate_bootstrap_ci.png\", dpi=300)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665087d5",
   "metadata": {},
   "source": [
    "## High toxicity ratio (IC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca78f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''tox_ci = summarize_ci(df_sub, \"target_politician\", \"tox_high_03\", bootstrap_ci_prop)\n",
    "tox_ci[\"err_low\"] = tox_ci[\"mid\"] - tox_ci[\"low\"]\n",
    "tox_ci[\"err_high\"] = tox_ci[\"high\"] - tox_ci[\"mid\"]\n",
    "tox_ci = tox_ci.set_index(\"target_politician\").loc[order].reset_index()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "ax = plt.gca()\n",
    "ax.bar(\n",
    "    tox_ci[\"target_politician\"],\n",
    "    tox_ci[\"mid\"],\n",
    "    yerr=[tox_ci[\"err_low\"], tox_ci[\"err_high\"]],\n",
    "    capsize=6\n",
    ")\n",
    "ax.set_ylim(0, 0.1)  # ajusta segÃºn tus tasas; 0â€“1 si prefieres\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"P(toxicity â‰¥ 0.30) (bootstrap 95% CI)\")\n",
    "ax.set_title(\"High-toxicity tweets by politician\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/tox_high_bootstrap_ci.png\", dpi=300)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c5d18",
   "metadata": {},
   "source": [
    "# Monthly time series (negativity and toxicity), with smoothing and CI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c02403",
   "metadata": {},
   "source": [
    "## Monthly aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae08605",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Asegura month\n",
    "if \"month\" not in df.columns:\n",
    "    df[\"month\"] = pd.to_datetime(df[\"timestamp\"]).dt.to_period(\"M\").astype(str)\n",
    "\n",
    "monthly = (\n",
    "    df[df[\"target_politician\"].isin(order)]\n",
    "      .groupby([\"month\",\"target_politician\"])\n",
    "      .agg(\n",
    "          n=(\"comment_id\", \"count\"),\n",
    "          neg_rate=(\"is_negative\", \"mean\"),\n",
    "          tox_mean=(\"toxicity\", \"mean\"),\n",
    "          tox_high=(\"tox_high_03\", \"mean\"),\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Convertir month a fecha para graficar\n",
    "monthly[\"month_date\"] = pd.to_datetime(monthly[\"month\"] + \"-01\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcb93e6",
   "metadata": {},
   "source": [
    "## â€œBinomialâ€ confidence bands for proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''z = 1.96\n",
    "monthly[\"neg_se\"] = np.sqrt(monthly[\"neg_rate\"]*(1-monthly[\"neg_rate\"]) / monthly[\"n\"])\n",
    "monthly[\"neg_low\"] = (monthly[\"neg_rate\"] - z*monthly[\"neg_se\"]).clip(0,1)\n",
    "monthly[\"neg_high\"] = (monthly[\"neg_rate\"] + z*monthly[\"neg_se\"]).clip(0,1)\n",
    "\n",
    "monthly[\"tox_se\"] = np.sqrt(monthly[\"tox_high\"]*(1-monthly[\"tox_high\"]) / monthly[\"n\"])\n",
    "monthly[\"tox_low\"] = (monthly[\"tox_high\"] - z*monthly[\"tox_se\"]).clip(0,1)\n",
    "monthly[\"tox_high_ci\"] = (monthly[\"tox_high\"] + z*monthly[\"tox_se\"]).clip(0,1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf94e2f",
   "metadata": {},
   "source": [
    "## Plot: Negativeness per month with band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641c79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plt.figure(figsize=(10,4))\n",
    "ax = plt.gca()\n",
    "\n",
    "for pol in order:\n",
    "    sub = monthly[monthly[\"target_politician\"] == pol].sort_values(\"month_date\")\n",
    "    ax.plot(sub[\"month_date\"], sub[\"neg_rate\"], label=pol)\n",
    "    ax.fill_between(sub[\"month_date\"], sub[\"neg_low\"], sub[\"neg_high\"], alpha=0.2)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Negative rate\")\n",
    "ax.set_title(\"Monthly negative rate (95% CI)\")\n",
    "ax.legend(frameon=False)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/timeseries_neg_rate_ci.png\", dpi=300)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b0c5a",
   "metadata": {},
   "source": [
    "## Plot: High toxicity per month with band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f35c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plt.figure(figsize=(10,4))\n",
    "ax = plt.gca()\n",
    "\n",
    "for pol in order:\n",
    "    sub = monthly[monthly[\"target_politician\"] == pol].sort_values(\"month_date\")\n",
    "    ax.plot(sub[\"month_date\"], sub[\"tox_high\"], label=pol)\n",
    "    ax.fill_between(sub[\"month_date\"], sub[\"tox_low\"], sub[\"tox_high_ci\"], alpha=0.2)\n",
    "\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"P(toxicity â‰¥ 0.30)\")\n",
    "ax.set_title(\"Monthly high-toxicity rate (95% CI)\")\n",
    "ax.legend(frameon=False)\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/timeseries_tox_high_ci.png\", dpi=300)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2090eb",
   "metadata": {},
   "source": [
    "# Plot: High toxicity per month with band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c86c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def pivot_diff(monthly, metric, pol1, pol2):\n",
    "    piv = monthly.pivot(index=\"month_date\", columns=\"target_politician\", values=metric)\n",
    "    return (piv[pol2] - piv[pol1]).dropna()\n",
    "\n",
    "diff_neg = pivot_diff(monthly, \"neg_rate\", \"Emmanuel Macron\", \"Marine Le Pen\")\n",
    "diff_tox = pivot_diff(monthly, \"tox_high\", \"Emmanuel Macron\", \"Marine Le Pen\")\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "ax = plt.gca()\n",
    "ax.plot(diff_neg.index, diff_neg.values)\n",
    "ax.axhline(0, linestyle=\"--\", linewidth=1)\n",
    "ax.set_title(\"Monthly gap in negativity (Le Pen âˆ’ Macron)\")\n",
    "ax.set_ylabel(\"Î” negative rate\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/timeseries_gap_neg.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,3.5))\n",
    "ax = plt.gca()\n",
    "ax.plot(diff_tox.index, diff_tox.values)\n",
    "ax.axhline(0, linestyle=\"--\", linewidth=1)\n",
    "ax.set_title(\"Monthly gap in high toxicity (Le Pen âˆ’ Macron)\")\n",
    "ax.set_ylabel(\"Î” P(tox â‰¥ 0.30)\")\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{FIG_DIR}/timeseries_gap_tox.png\", dpi=300)\n",
    "plt.show()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "css_full",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
